apiVersion: 1

groups:
  - orgId: 1
    name: pedro_critical_alerts
    folder: Pedro Bot Alerts
    interval: 1m
    rules:
      - uid: pedro_twitch_offline
        title: Twitch Bot Offline
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: twitch_connection_count
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 2m
        annotations:
          summary: Twitch bot connection is down
          description: The Twitch bot has no active connection. Bot is offline.
        labels:
          severity: critical
          service: twitch

      - uid: pedro_discord_high_errors
        title: Discord Bot High Error Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: sum(rate(discord_command_errors[5m])) / (sum(rate(discord_command_total[5m])) + 0.001)
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.2
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 3m
        annotations:
          summary: Discord command error rate is {{ printf "%.1f" $values.A.Value }}%
          description: More than 20% of Discord commands are failing. Check Discord bot logs.
        labels:
          severity: critical
          service: discord

      - uid: pedro_vllm_offline
        title: vLLM Service Down
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: up{job=~"vllm.*|llm.*"}
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 1
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 2m
        annotations:
          summary: vLLM service is DOWN
          description: The vLLM service is not responding. All LLM functionality is unavailable.
        labels:
          severity: critical
          service: vllm

      - uid: pedro_llm_high_failures
        title: High LLM Failure Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(failed_llm_gen_count[5m]) / (rate(successful_llm_gen_count[5m]) + rate(failed_llm_gen_count[5m]) + 0.001)
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.15
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          summary: LLM failure rate is {{ printf "%.1f" (mul $values.A.Value 100) }}%
          description: More than 15% of LLM calls are failing. Check vLLM service and logs.
        labels:
          severity: critical
          service: llm

  - orgId: 1
    name: pedro_warning_alerts
    folder: Pedro Bot Alerts
    interval: 2m
    rules:
      - uid: pedro_vllm_high_ttft
        title: vLLM High Time to First Token
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: histogram_quantile(0.95, sum(rate(vllm:time_to_first_token_seconds_bucket[5m])) by (le, model_name))
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 1.0
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          summary: vLLM p95 TTFT is {{ printf "%.2f" $values.A.Value }}s
          description: Time to first token latency is high. Users experiencing slow responses.
        labels:
          severity: warning
          service: vllm

      - uid: pedro_vllm_high_e2e_latency
        title: vLLM High End-to-End Latency
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: histogram_quantile(0.95, sum(rate(vllm:e2e_request_latency_seconds_bucket[5m])) by (le, model_name))
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 3.0
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          summary: vLLM p95 E2E latency is {{ printf "%.2f" $values.A.Value }}s
          description: End-to-end request latency is above 3 seconds. Check vLLM performance.
        labels:
          severity: warning
          service: vllm

      - uid: pedro_vllm_cache_high
        title: vLLM KV Cache High Usage
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: vllm:kv_cache_usage_perc
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.85
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 3m
        annotations:
          summary: vLLM KV cache usage is {{ printf "%.1f" (mul $values.A.Value 100) }}%
          description: KV cache is above 85% capacity. May impact performance soon.
        labels:
          severity: warning
          service: vllm

      - uid: pedro_vllm_queue_backup
        title: vLLM Request Queue Backing Up
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: vllm:num_requests_waiting
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 10
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 2m
        annotations:
          summary: vLLM has {{ $values.A.Value }} requests waiting
          description: Request queue depth is high. vLLM may be overloaded.
        labels:
          severity: warning
          service: vllm

      - uid: pedro_empty_responses
        title: High Empty LLM Response Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(empty_llm_response_count[5m]) / (rate(successful_llm_gen_count[5m]) + 0.001)
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.25
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          summary: Empty response rate is {{ printf "%.1f" (mul $values.A.Value 100) }}%
          description: More than 25% of LLM responses are empty. Check model configuration.
        labels:
          severity: warning
          service: llm

      - uid: pedro_web_search_failures
        title: Web Search High Failure Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(web_search_fail_count[5m]) / (rate(web_search_success_count[5m]) + rate(web_search_fail_count[5m]) + 0.001)
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.3
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          summary: Web search failure rate is {{ printf "%.1f" (mul $values.A.Value 100) }}%
          description: More than 30% of web searches are failing. Check DuckDuckGo integration.
        labels:
          severity: warning
          service: web_search

      - uid: pedro_discord_slow_commands
        title: Discord Commands Slow
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: histogram_quantile(0.95, sum(rate(discord_command_duration_seconds_bucket[5m])) by (command, le))
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 5.0
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 3m
        annotations:
          summary: Discord command p95 latency is {{ printf "%.2f" $values.A.Value }}s
          description: Discord commands are taking longer than 5 seconds. Check performance.
        labels:
          severity: warning
          service: discord

  - orgId: 1
    name: pedro_info_alerts
    folder: Pedro Bot Alerts
    interval: 5m
    rules:
      - uid: pedro_memory_high
        title: High Memory Usage
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              expr: go_memstats_heap_alloc_bytes
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 100000000
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 10m
        annotations:
          summary: Bot memory usage is {{ humanize1024 $values.A.Value }}
          description: Heap allocation is above 100MB. Monitor for memory leaks.
        labels:
          severity: info
          service: bot

      - uid: pedro_vllm_memory_high
        title: vLLM High Memory Usage
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              expr: process_resident_memory_bytes{job=~"vllm.*|llm.*"}
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
          - refId: C
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 2000000000
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - A
                  reducer:
                    params: []
                    type: last
                  type: query
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              intervalMs: 1000
              maxDataPoints: 43200
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 10m
        annotations:
          summary: vLLM memory usage is {{ humanize1024 $values.A.Value }}
          description: vLLM memory is above 2GB. Monitor for issues.
        labels:
          severity: info
          service: vllm
